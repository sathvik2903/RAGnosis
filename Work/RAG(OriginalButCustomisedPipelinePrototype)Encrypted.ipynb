{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNyCFp-ca2HG",
        "outputId": "1b1fbb64-923b-408c-aff5-25e770d126f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ All libraries imported successfully\n",
            "âœ“ Neo4jConnector class defined\n",
            "âœ“ BiomedicalRAG class defined with fallback support\n",
            "âœ“ CompleteRAGPipeline class defined\n",
            "\n",
            "======================================================================\n",
            "CONNECTING TO NEO4J AURA\n",
            "======================================================================\n",
            "âœ“ Connected to Neo4j at neo4j+s://62418b31.databases.neo4j.io\n",
            "\n",
            "======================================================================\n",
            "DATABASE EXPLORATION\n",
            "======================================================================\n",
            "\n",
            "ðŸ“‹ Database Schema:\n",
            "{\n",
            "  \"node_labels\": [\n",
            "    \"[Info Tree Node]\",\n",
            "    \"[Info Tree Root]\",\n",
            "    \"[Disease]\",\n",
            "    \"[Embedding Root]\",\n",
            "    \"[Embedding Node, pseudo medical history Embedding Node]\",\n",
            "    \"[Embedding Node, diagnosis info Embedding Node]\",\n",
            "    \"Disease\",\n",
            "    \"Info Tree Node\",\n",
            "    \"EntityCanonical\"\n",
            "  ],\n",
            "  \"relationship_types\": [\n",
            "    \"tree_node-tree_node\",\n",
            "    \"tree_root-tree_node\",\n",
            "    \"main_node-tree_root\",\n",
            "    \"main_node-embedding_root\",\n",
            "    \"embedding_root-embedding_node\",\n",
            "    \"CANONICAL_FORM\",\n",
            "    \"SIMILAR_TO\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "ðŸ“Š Sample Data:\n",
            "[\n",
            "  {\n",
            "    \"labels\": [\n",
            "      \"[Info Tree Node]\"\n",
            "    ],\n",
            "    \"props\": {\n",
            "      \"text\": \"Diaphragmatic hernia\",\n",
            "      \"original_id\": \"4:77316bc7-08a7-42a4-afdd-da77a7c4cd66:4\",\n",
            "      \"canonical_id\": \"7f8f9fc7c290b76be3b74b10089d3c142d559ed4\",\n",
            "      \"canonical_name\": \"Diaphragmatic hernia\",\n",
            "      \"embedding\": [\n",
            "        0.03576311469078064,\n",
            "        0.05286271497607231,\n",
            "        -0.04229522868990898,\n",
            "        -0.04544904828071594,\n",
            "        -0.11224014312028885,\n",
            "        -0.05325174704194069,\n",
            "        0.10214173048734665,\n",
            "        0.04705153405666351,\n",
            "        0.009191337041556835,\n",
            "        0.04076378792524338,\n",
            "        -0.06799399852752686,\n",
            "        0.02525498904287815,\n",
            "        0.07520461827516556,\n",
            "        0.039422668516635895,\n",
            "        -0.01937039941549301,\n",
            "        -0.033995967358350754,\n",
            "        0.0354953296482563,\n",
            "        -0.05318506807088852,\n",
            "        -0.05390996113419533,\n",
            "        0.02657420001924038,\n",
            "        -0.010321310721337795,\n",
            "        0.10531290620565414,\n",
            "        -0.019697150215506554,\n",
            "        0.017558163031935692,\n",
            "        0.06206679716706276,\n",
            "        0.005032901186496019,\n",
            "        0.06529197096824646,\n",
            "        -0.014074660837650299,\n",
            "        0.004305678885430098,\n",
            "        -0.08756348490715027,\n",
            "        -0.05562986060976982,\n",
            "        -0.031473636627197266,\n",
            "        0.06136273220181465,\n",
            "        0.01120613981038332,\n",
            "        0.07497111707925797,\n",
            "        -0.0018683535745367408,\n",
            "        0.030764836817979813,\n",
            "        0.03140702843666077,\n",
            "        -0.08962243795394897,\n",
            "        0.012977320700883865,\n",
            "        -0.04972457513213158,\n",
            "        0.0028449774254113436,\n",
            "        -0.040089599788188934,\n",
            "        0.02791019156575203,\n",
            "        -0.04995465651154518,\n",
            "        0.07484719157218933,\n",
            "        -0.055136680603027344,\n",
            "        0.0407584011554718,\n",
            "        0.047334540635347366,\n",
            "        0.02707740291953087,\n",
            "        -0.060189951211214066,\n",
            "        -0.04394541680812836,\n",
            "        0.009555946104228497,\n",
            "        0.06063959747552872,\n",
            "        -0.042911604046821594,\n",
            "        -0.013287222012877464,\n",
            "        -0.014029809273779392,\n",
            "        0.06864794343709946,\n",
            "        -0.0465916283428669,\n",
            "        -0.03245644271373749,\n",
            "        0.048023588955402374,\n",
            "        -0.018127668648958206,\n",
            "        0.02929253876209259,\n",
            "        -0.00947472732514143,\n",
            "        0.03803268447518349,\n",
            "        0.00782723631709814,\n",
            "        0.03571104630827904,\n",
            "        -0.016696855425834656,\n",
            "        0.0399298332631588,\n",
            "        0.010594724677503109,\n",
            "        0.05924060568213463,\n",
            "        -0.027906667441129684,\n",
            "        -0.022924132645130157,\n",
            "        0.04351767152547836,\n",
            "        0.024261776357889175,\n",
            "        -0.03769078850746155,\n",
            "        -0.00444845762103796,\n",
            "        0.010029605589807034,\n",
            "        0.08287197351455688,\n",
            "        0.027780471369624138,\n",
            "        -0.0008966869791038334,\n",
            "        0.06658414751291275,\n",
            "        -0.06247902661561966,\n",
            "        0.008276090957224369,\n",
            "        0.002617976628243923,\n",
            "        0.08594992011785507,\n",
            "        -0.010375394485890865,\n",
            "        -0.009077801369130611,\n",
            "        -0.05968756601214409,\n",
            "        -0.06544332951307297,\n",
            "        -0.024316363036632538,\n",
            "        -0.06899973005056381,\n",
            "        -0.06512129306793213,\n",
            "        0.026472249999642372,\n",
            "        -0.04552649334073067,\n",
            "        -0.006537488661706448,\n",
            "        -0.0010519918287172914,\n",
            "        -0.03477459028363228,\n",
            "        0.03473518043756485,\n",
            "        0.01915956661105156,\n",
            "        0.00013095488247927278,\n",
            "        0.021811340004205704,\n",
            "        0.03437908738851547,\n",
            "        0.04134494811296463,\n",
            "        -0.03896315395832062,\n",
            "        -0.04402943700551987,\n",
            "        0.058997392654418945,\n",
            "        -0.07353968918323517,\n",
            "        0.030647166073322296,\n",
            "        0.02668931521475315,\n",
            "        -0.004394661635160446,\n",
            "        0.07663210481405258,\n",
            "        -0.00203215004876256,\n",
            "        -0.007365607190877199,\n",
            "        0.003990964964032173,\n",
            "        0.10232284665107727,\n",
            "        -0.004523274023085833,\n",
            "        -0.02846076339483261,\n",
            "        0.027774110436439514,\n",
            "        -0.03341556340456009,\n",
            "        -0.06545860320329666,\n",
            "        -0.03695356100797653,\n",
            "        -0.020099028944969177,\n",
            "        0.06259946525096893,\n",
            "        -0.06712111830711365,\n",
            "        -0.101467065513134,\n",
            "        -0.14567683637142181,\n",
            "        1.2035228197561949e-33,\n",
            "        -0.04159625247120857,\n",
            "        -0.05179448053240776,\n",
            "        0.05420349910855293,\n",
            "        0.01552300900220871,\n",
            "        -0.021516947075724602,\n",
            "        0.0408780574798584,\n",
            "        -0.015128297731280327,\n",
            "        -0.04314948618412018,\n",
            "        0.13569463789463043,\n",
            "        -0.11124057322740555,\n",
            "        -0.09065138548612595,\n",
            "        -0.015937581658363342,\n",
            "        0.06688099354505539,\n",
            "        -0.029844053089618683,\n",
            "        0.005187240429222584,\n",
            "        -0.03323345258831978,\n",
            "        -0.055818796157836914,\n",
            "        0.07479580491781235,\n",
            "        -0.06158725544810295,\n",
            "        -0.0149685675278306,\n",
            "        0.0680246502161026,\n",
            "        0.12359003722667694,\n",
            "        0.006115896161645651,\n",
            "        0.010274969041347504,\n",
            "        -0.005708434619009495,\n",
            "        0.010979237966239452,\n",
            "        0.03947293385863304,\n",
            "        -0.04660836234688759,\n",
            "        0.019858267158269882,\n",
            "        0.04595566913485527,\n",
            "        0.061904214322566986,\n",
            "        -0.03304795175790787,\n",
            "        0.03357097506523132,\n",
            "        0.05777842923998833,\n",
            "        -0.0854751318693161,\n",
            "        0.03083181381225586,\n",
            "        -0.056207023561000824,\n",
            "        0.034545112401247025,\n",
            "        -0.06545702368021011,\n",
            "        0.07464979588985443,\n",
            "        -0.09198987483978271,\n",
            "        0.002483495743945241,\n",
            "        0.0026580863632261753,\n",
            "        0.017816178500652313,\n",
            "        0.002805491676554084,\n",
            "        -0.07521276921033859,\n",
            "        0.03719836473464966,\n",
            "        0.03890776261687279,\n",
            "        -0.04237682744860649,\n",
            "        -0.032779984176158905,\n",
            "        0.05861898139119148,\n",
            "        0.08296021074056625,\n",
            "        0.07540968805551529,\n",
            "        -0.10353618115186691,\n",
            "        -0.027305062860250473,\n",
            "        0.010905708186328411,\n",
            "        0.01906520314514637,\n",
            "        -0.06253249198198318,\n",
            "        0.03416784852743149,\n",
            "        0.07724741846323013,\n",
            "        0.10213049501180649,\n",
            "        0.038227424025535583,\n",
            "        0.024952489882707596,\n",
            "        0.06455127894878387,\n",
            "        0.013087752275168896,\n",
            "        0.010502312332391739,\n",
            "        0.008784376084804535,\n",
            "        0.004568102769553661,\n",
            "        0.036417096853256226,\n",
            "        0.02800923027098179,\n",
            "        -0.07960795611143112,\n",
            "        -0.03780830651521683,\n",
            "        -0.0008457258809357882,\n",
            "        0.043545033782720566,\n",
            "        -0.018647054210305214,\n",
            "        -0.006791188381612301,\n",
            "        0.010159122757613659,\n",
            "        0.025977831333875656,\n",
            "        -0.07712595909833908,\n",
            "        -0.09395104646682739,\n",
            "        0.0839189738035202,\n",
            "        -0.0795961245894432,\n",
            "        0.06278540939092636,\n",
            "        0.05543864145874977,\n",
            "        0.028666771948337555,\n",
            "        -0.013107320293784142,\n",
            "        -0.0036920898128300905,\n",
            "        -0.010081471875309944,\n",
            "        -0.05798652768135071,\n",
            "        0.08355798572301865,\n",
            "        -0.03470771759748459,\n",
            "        0.03732944279909134,\n",
            "        0.028505491092801094,\n",
            "        0.021096793934702873,\n",
            "        -0.01039471197873354,\n",
            "        -2.0252355234737104e-33,\n",
            "        0.08301342278718948,\n",
            "        -0.035216137766838074,\n",
            "        -0.03861887753009796,\n",
            "        0.06344330310821533,\n",
            "        0.061974190175533295,\n",
            "        -0.012784160673618317,\n",
            "        -0.016570035368204117,\n",
            "        0.10561951994895935,\n",
            "        -0.09072191268205643,\n",
            "        -0.008959337137639523,\n",
            "        0.07161415368318558,\n",
            "        -0.04922424256801605,\n",
            "        0.014904986135661602,\n",
            "        -0.007410963997244835,\n",
            "        0.04634168744087219,\n",
            "        0.039725832641124725,\n",
            "        0.03133433312177658,\n",
            "        0.00510540371760726,\n",
            "        -0.056322332471609116,\n",
            "        0.07101514935493469,\n",
            "        -0.07451187074184418,\n",
            "        -0.041634343564510345,\n",
            "        -0.07583381235599518,\n",
            "        -0.09314505010843277,\n",
            "        -0.00019647079170681536,\n",
            "        0.04043632000684738,\n",
            "        0.01707639917731285,\n",
            "        -0.023695601150393486,\n",
            "        -0.04024858400225639,\n",
            "        -0.028285861015319824,\n",
            "        0.0075256675481796265,\n",
            "        0.04571088030934334,\n",
            "        -0.045431241393089294,\n",
            "        -0.0861733928322792,\n",
            "        -0.01106532383710146,\n",
            "        -0.0014544394798576832,\n",
            "        -0.12238556891679764,\n",
            "        -0.08054696023464203,\n",
            "        -0.019991498440504074,\n",
            "        -0.10693260282278061,\n",
            "        0.01494152657687664,\n",
            "        -0.0342114083468914,\n",
            "        0.14676079154014587,\n",
            "        0.024858592078089714,\n",
            "        0.0027754700277000666,\n",
            "        -0.017369162291288376,\n",
            "        -0.0274677611887455,\n",
            "        -0.021387098357081413,\n",
            "        0.009897369891405106,\n",
            "        0.023567471653223038,\n",
            "        0.005596760660409927,\n",
            "        0.04247207194566727,\n",
            "        0.02577158994972706,\n",
            "        0.008926588110625744,\n",
            "        0.07484449446201324,\n",
            "        0.005708713550120592,\n",
            "        -0.08829453587532043,\n",
            "        0.007128557655960321,\n",
            "        0.03011396713554859,\n",
            "        0.05161041021347046,\n",
            "        0.008587324991822243,\n",
            "        -0.0026464795228093863,\n",
            "        -0.002917822217568755,\n",
            "        -0.03807976469397545,\n",
            "        0.08344893902540207,\n",
            "        0.05078656226396561,\n",
            "        -0.05275474861264229,\n",
            "        -0.07464899867773056,\n",
            "        -0.06316936761140823,\n",
            "        0.07160734385251999,\n",
            "        0.026814455166459084,\n",
            "        0.02234388142824173,\n",
            "        -0.005212654825299978,\n",
            "        0.07781021296977997,\n",
            "        -0.01388792134821415,\n",
            "        0.017544707283377647,\n",
            "        0.04372917115688324,\n",
            "        -0.07851698994636536,\n",
            "        0.06492909044027328,\n",
            "        0.028251376003026962,\n",
            "        -0.03458836302161217,\n",
            "        0.011565713211894035,\n",
            "        0.06816168129444122,\n",
            "        -0.005407640710473061,\n",
            "        0.011001624166965485,\n",
            "        0.01217125728726387,\n",
            "        -0.017426079139113426,\n",
            "        0.05019564554095268,\n",
            "        -0.07107195258140564,\n",
            "        0.00026418259949423373,\n",
            "        0.05482755973935127,\n",
            "        -0.027399864047765732,\n",
            "        -0.08044402301311493,\n",
            "        -0.010437953285872936,\n",
            "        0.13540378212928772,\n",
            "        -1.696865936651193e-08,\n",
            "        0.010823202319443226,\n",
            "        -0.0009033763199113309,\n",
            "        -0.02899923361837864,\n",
            "        -0.013550366275012493,\n",
            "        -0.04762919992208481,\n",
            "        -0.08040055632591248,\n",
            "        0.05554172396659851,\n",
            "        -0.006309219636023045,\n",
            "        -0.04675564542412758,\n",
            "        -0.06617730110883713,\n",
            "        -0.01252307090908289,\n",
            "        -0.022791190072894096,\n",
            "        0.0419994592666626,\n",
            "        -0.045899201184511185,\n",
            "        -0.059210117906332016,\n",
            "        -0.058916203677654266,\n",
            "        -0.01854575052857399,\n",
            "        0.08010836690664291,\n",
            "        -0.026592273265123367,\n",
            "        -0.0801958441734314,\n",
            "        -0.0014869794249534607,\n",
            "        -0.08028513193130493,\n",
            "        0.007039674557745457,\n",
            "        -0.027939001098275185,\n",
            "        0.04897332563996315,\n",
            "        0.026705794036388397,\n",
            "        -0.03277479484677315,\n",
            "        0.035663869231939316,\n",
            "        0.06656989455223083,\n",
            "        -0.0721835047006607,\n",
            "        0.005795918405056,\n",
            "        0.0471620112657547,\n",
            "        0.015109988860785961,\n",
            "        -0.09289281070232391,\n",
            "        -0.1430584192276001,\n",
            "        0.020505748689174652,\n",
            "        0.05205048248171806,\n",
            "        0.022026218473911285,\n",
            "        0.023910339921712875,\n",
            "        -0.05515463650226593,\n",
            "        0.027669120579957962,\n",
            "        -0.04046553000807762,\n",
            "        0.13183629512786865,\n",
            "        0.006510382052510977,\n",
            "        0.025392752140760422,\n",
            "        0.00875540915876627,\n",
            "        -0.008909573778510094,\n",
            "        -0.01983533427119255,\n",
            "        -0.025777213275432587,\n",
            "        -0.030387597158551216,\n",
            "        0.02202247828245163,\n",
            "        -0.013217408210039139,\n",
            "        0.09380371123552322,\n",
            "        0.04345263913273811,\n",
            "        -0.07298486679792404,\n",
            "        0.06975560635328293,\n",
            "        -0.0624568797647953,\n",
            "        -0.028234435245394707,\n",
            "        -0.06479549407958984,\n",
            "        0.07529119402170181,\n",
            "        -0.00823371671140194,\n",
            "        -0.018131639808416367,\n",
            "        0.0070863571017980576,\n",
            "        0.034476496279239655\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"labels\": [\n",
            "      \"[Info Tree Node]\"\n",
            "    ],\n",
            "    \"props\": {\n",
            "      \"text\": \"Causes\",\n",
            "      \"original_id\": \"4:77316bc7-08a7-42a4-afdd-da77a7c4cd66:8\",\n",
            "      \"canonical_id\": \"cc59a1bcb9f06ec16b56d200c21de16fdac5f7ee\",\n",
            "      \"canonical_name\": \"Causes\",\n",
            "      \"embedding\": [\n",
            "        -0.04784803465008736,\n",
            "        0.02248946763575077,\n",
            "        0.07446396350860596,\n",
            "        0.08186126500368118,\n",
            "        0.07142410427331924,\n",
            "        0.005762580782175064,\n",
            "        0.046554841101169586,\n",
            "        0.0673946663737297,\n",
            "        -0.008740192279219627,\n",
            "        0.03733837604522705,\n",
            "        -0.01884577050805092,\n",
            "        -0.02810056507587433,\n",
            "        -0.012911870144307613,\n",
            "        -0.013467609882354736,\n",
            "        -0.02926226705312729,\n",
            "        -0.03503994643688202,\n",
            "        -0.07046747207641602,\n",
            "        -0.07934803515672684,\n",
            "        -0.08694447576999664,\n",
            "        0.030763685703277588,\n",
            "        -0.04576443135738373,\n",
            "        -0.0020828668493777514,\n",
            "        -0.01718265749514103,\n",
            "        -0.0005913276108913124,\n",
            "        -0.14966699481010437,\n",
            "        -0.019956843927502632,\n",
            "        0.022602610290050507,\n",
            "        -0.05177132040262222,\n",
            "        0.09224521368741989,\n",
            "        -0.07261581718921661,\n",
            "        0.016208436340093613,\n",
            "        0.037911154329776764,\n",
            "        -0.015913719311356544,\n",
            "        0.006501920986920595,\n",
            "        -0.010348259471356869,\n",
            "        0.023207126185297966,\n",
            "        0.010577144101262093,\n",
            "        0.05030693858861923,\n",
            "        -0.00949331559240818,\n",
            "        0.0036137511488050222,\n",
            "        -0.003782152198255062,\n",
            "        -0.08801719546318054,\n",
            "        -0.005494832061231136,\n",
            "        -0.005979720037430525,\n",
            "        -0.004514928907155991,\n",
            "        -0.01689762994647026,\n",
            "        0.03755318000912666,\n",
            "        0.045562732964754105,\n",
            "        -0.014376078732311726,\n",
            "        0.0007264416781254113,\n",
            "        -0.05453614890575409,\n",
            "        -0.05010216683149338,\n",
            "        0.032703887671232224,\n",
            "        -0.028849080204963684,\n",
            "        0.04574060067534447,\n",
            "        -0.12204291671514511,\n",
            "        0.030828749760985374,\n",
            "        0.042643409222364426,\n",
            "        0.004659160505980253,\n",
            "        0.016828376799821854,\n",
            "        0.034149255603551865,\n",
            "        0.0015594579745084047,\n",
            "        -0.11218322068452835,\n",
            "        0.021066777408123016,\n",
            "        0.12135051190853119,\n",
            "        0.05667605996131897,\n",
            "        0.03319916874170303,\n",
            "        0.03169666975736618,\n",
            "        -0.019419141113758087,\n",
            "        0.11036982387304306,\n",
            "        0.08630375564098358,\n",
            "        -0.021178482100367546,\n",
            "        -0.06663667410612106,\n",
            "        0.012218475341796875,\n",
            "        0.06173514574766159,\n",
            "        0.014345637522637844,\n",
            "        -0.06459501385688782,\n",
            "        -0.025789961218833923,\n",
            "        0.04358024150133133,\n",
            "        0.02435835264623165,\n",
            "        0.07748060673475266,\n",
            "        0.03657901659607887,\n",
            "        -0.016926107928156853,\n",
            "        0.025800997391343117,\n",
            "        0.09739677608013153,\n",
            "        -0.05303711071610451,\n",
            "        0.0833386704325676,\n",
            "        -0.06699049472808838,\n",
            "        -0.05123777315020561,\n",
            "        0.06155426800251007,\n",
            "        -0.03708919882774353,\n",
            "        -0.06979469954967499,\n",
            "        0.09531533718109131,\n",
            "        0.03551425039768219,\n",
            "        -0.003239076817408204,\n",
            "        0.047495946288108826,\n",
            "        0.01766323298215866,\n",
            "        -0.0856814906001091,\n",
            "        0.006866684649139643,\n",
            "        0.17231513559818268,\n",
            "        0.004620014689862728,\n",
            "        0.011588197201490402,\n",
            "        0.029096506536006927,\n",
            "        0.11679717898368835,\n",
            "        0.0633375346660614,\n",
            "        -0.07278431951999664,\n",
            "        0.005978022236377001,\n",
            "        -0.0384373813867569,\n",
            "        -0.022243255749344826,\n",
            "        -0.020412003621459007,\n",
            "        0.02299918606877327,\n",
            "        0.028830232098698616,\n",
            "        0.04272286593914032,\n",
            "        -0.07706362754106522,\n",
            "        0.06847918033599854,\n",
            "        -0.034740135073661804,\n",
            "        0.07849116623401642,\n",
            "        -0.012033066712319851,\n",
            "        -0.08367772400379181,\n",
            "        -0.010702233761548996,\n",
            "        -0.014431901276111603,\n",
            "        -0.001211259514093399,\n",
            "        -0.08837126195430756,\n",
            "        0.04011917486786842,\n",
            "        -0.0841982364654541,\n",
            "        -0.11449480801820755,\n",
            "        -0.10389052331447601,\n",
            "        -5.219864214746956e-33,\n",
            "        0.03938545286655426,\n",
            "        -0.09246858954429626,\n",
            "        -0.029572971165180206,\n",
            "        0.042396750301122665,\n",
            "        0.025447538122534752,\n",
            "        0.011871478520333767,\n",
            "        -0.03679336979985237,\n",
            "        -0.036589305847883224,\n",
            "        0.020541619509458542,\n",
            "        0.011045674793422222,\n",
            "        0.01943451166152954,\n",
            "        -0.04247727245092392,\n",
            "        0.014701026491820812,\n",
            "        -0.05855843052268028,\n",
            "        0.05959880352020264,\n",
            "        -0.010469678789377213,\n",
            "        -0.08119415491819382,\n",
            "        0.0009411000646650791,\n",
            "        -0.04552764818072319,\n",
            "        0.010515749454498291,\n",
            "        -0.01919076405465603,\n",
            "        -0.04740223288536072,\n",
            "        -0.003796243341639638,\n",
            "        -0.02249947376549244,\n",
            "        -0.07170828431844711,\n",
            "        0.015252948738634586,\n",
            "        -0.05341624096035957,\n",
            "        -0.05244101211428642,\n",
            "        0.039139989763498306,\n",
            "        0.01068073883652687,\n",
            "        0.048654112964868546,\n",
            "        0.00698896124958992,\n",
            "        -0.0026914195623248816,\n",
            "        -0.021811580285429955,\n",
            "        -0.03527352586388588,\n",
            "        -0.023135539144277573,\n",
            "        -0.023320302367210388,\n",
            "        -0.03530670702457428,\n",
            "        -0.009496287442743778,\n",
            "        -0.014235605485737324,\n",
            "        -0.08636897057294846,\n",
            "        0.017692582681775093,\n",
            "        -0.03292306140065193,\n",
            "        0.008466681465506554,\n",
            "        0.0905059352517128,\n",
            "        -0.005974270403385162,\n",
            "        0.025361429899930954,\n",
            "        -0.06465160846710205,\n",
            "        -0.0904337465763092,\n",
            "        0.04468405619263649,\n",
            "        -0.03173615410923958,\n",
            "        0.035893574357032776,\n",
            "        0.0017743431963026524,\n",
            "        0.0021875244565308094,\n",
            "        0.016732219606637955,\n",
            "        -0.013098355382680893,\n",
            "        0.01868821121752262,\n",
            "        -0.05774468183517456,\n",
            "        -0.00943104736506939,\n",
            "        0.02967819571495056,\n",
            "        0.04062677547335625,\n",
            "        0.030896266922354698,\n",
            "        -0.01333940401673317,\n",
            "        0.10730357468128204,\n",
            "        -0.015384233556687832,\n",
            "        -0.07971751689910889,\n",
            "        0.05147354677319527,\n",
            "        -0.06684578955173492,\n",
            "        -0.061918843537569046,\n",
            "        0.014462639577686787,\n",
            "        -0.03573640435934067,\n",
            "        -0.01873066835105419,\n",
            "        -0.02479058876633644,\n",
            "        -0.03291667252779007,\n",
            "        -0.0004571905010379851,\n",
            "        0.015899905934929848,\n",
            "        -0.05893984064459801,\n",
            "        0.02738780528306961,\n",
            "        -0.05862553045153618,\n",
            "        -0.03359087556600571,\n",
            "        -0.05141724273562431,\n",
            "        -0.033659979701042175,\n",
            "        0.05978633090853691,\n",
            "        -0.034585997462272644,\n",
            "        -0.015893885865807533,\n",
            "        0.06211027130484581,\n",
            "        -0.027672607451677322,\n",
            "        -0.04446757212281227,\n",
            "        -0.022734371945261955,\n",
            "        0.008873005397617817,\n",
            "        0.05984743684530258,\n",
            "        -0.005850424524396658,\n",
            "        0.06176059693098068,\n",
            "        0.046350330114364624,\n",
            "        -0.030780985951423645,\n",
            "        2.2613221762348432e-33,\n",
            "        -0.09892649948596954,\n",
            "        -0.02436688169836998,\n",
            "        -0.04981375113129616,\n",
            "        -0.06753174215555191,\n",
            "        0.04860129952430725,\n",
            "        -0.01126042753458023,\n",
            "        -0.017759647220373154,\n",
            "        -0.005402769427746534,\n",
            "        0.013596600852906704,\n",
            "        0.01614411734044552,\n",
            "        -0.0401373952627182,\n",
            "        -0.05335190147161484,\n",
            "        0.009098466485738754,\n",
            "        0.061432234942913055,\n",
            "        -0.0034441843163222075,\n",
            "        -0.0678158551454544,\n",
            "        0.01647329144179821,\n",
            "        0.07517516613006592,\n",
            "        0.006521445699036121,\n",
            "        -0.041484858840703964,\n",
            "        -0.02588309347629547,\n",
            "        0.045648105442523956,\n",
            "        -0.027716197073459625,\n",
            "        -0.09675764292478561,\n",
            "        -0.05241797864437103,\n",
            "        0.050568610429763794,\n",
            "        -0.03118455968797207,\n",
            "        0.04400753602385521,\n",
            "        -0.013506685383617878,\n",
            "        0.0571117177605629,\n",
            "        0.02698129042983055,\n",
            "        0.09722652286291122,\n",
            "        -0.058280427008867264,\n",
            "        0.04744480550289154,\n",
            "        0.0037125067319720984,\n",
            "        0.12612174451351166,\n",
            "        0.00912261102348566,\n",
            "        0.007611445151269436,\n",
            "        -0.004186020232737064,\n",
            "        -0.03295718878507614,\n",
            "        0.06966597586870193,\n",
            "        0.002116360468789935,\n",
            "        0.12051709741353989,\n",
            "        0.06435278803110123,\n",
            "        0.047669291496276855,\n",
            "        -0.017211563885211945,\n",
            "        0.011916355229914188,\n",
            "        0.038139186799526215,\n",
            "        0.11500492691993713,\n",
            "        0.02061903104186058,\n",
            "        -0.011063669808208942,\n",
            "        0.0005137828993611038,\n",
            "        0.053976498544216156,\n",
            "        0.054988160729408264,\n",
            "        -0.013981375843286514,\n",
            "        -0.022319288924336433,\n",
            "        -0.054998643696308136,\n",
            "        -0.021075056865811348,\n",
            "        -0.0054099904373288155,\n",
            "        0.05875101312994957,\n",
            "        -0.010916370898485184,\n",
            "        0.07103955000638962,\n",
            "        -0.0539528951048851,\n",
            "        -0.037901610136032104,\n",
            "        0.05755895376205444,\n",
            "        -0.044808220118284225,\n",
            "        -0.015954528003931046,\n",
            "        -0.0058564250357449055,\n",
            "        0.12591686844825745,\n",
            "        -0.01526434812694788,\n",
            "        0.0010757570853456855,\n",
            "        0.0417061485350132,\n",
            "        -0.14559385180473328,\n",
            "        -0.0047009969130158424,\n",
            "        -0.05686211958527565,\n",
            "        0.05461941659450531,\n",
            "        -0.12323368340730667,\n",
            "        0.05933776870369911,\n",
            "        -0.00648914510384202,\n",
            "        -0.037509508430957794,\n",
            "        -0.05416424572467804,\n",
            "        -0.034681107848882675,\n",
            "        0.04614116996526718,\n",
            "        0.03061891347169876,\n",
            "        -0.12502913177013397,\n",
            "        -0.0016708801267668605,\n",
            "        0.0432412289083004,\n",
            "        0.005609617102891207,\n",
            "        0.04070068523287773,\n",
            "        -0.014879029244184494,\n",
            "        -0.021620264276862144,\n",
            "        -0.009244678542017937,\n",
            "        -0.05810796469449997,\n",
            "        0.033159200102090836,\n",
            "        0.009272574447095394,\n",
            "        -1.1925772369636434e-08,\n",
            "        0.01899615302681923,\n",
            "        -0.06074940040707588,\n",
            "        -0.04993264749646187,\n",
            "        0.002275909297168255,\n",
            "        0.04737480729818344,\n",
            "        -0.0052326517179608345,\n",
            "        -0.01497804094105959,\n",
            "        0.07009617984294891,\n",
            "        0.027311068028211594,\n",
            "        0.04100555554032326,\n",
            "        -0.08262210339307785,\n",
            "        0.09075666218996048,\n",
            "        -0.010370580479502678,\n",
            "        0.04899190366268158,\n",
            "        0.01845354586839676,\n",
            "        -0.030414892360568047,\n",
            "        -0.0299293864518404,\n",
            "        0.0676843598484993,\n",
            "        -0.002872644690796733,\n",
            "        -0.07170701026916504,\n",
            "        0.017671499401330948,\n",
            "        -0.0479474738240242,\n",
            "        0.03528393432497978,\n",
            "        0.03949394449591637,\n",
            "        -0.020843353122472763,\n",
            "        -0.02929726056754589,\n",
            "        0.05677274242043495,\n",
            "        0.05490022897720337,\n",
            "        -0.013811285607516766,\n",
            "        -0.048056092113256454,\n",
            "        0.048725150525569916,\n",
            "        0.01246302854269743,\n",
            "        -0.05266090855002403,\n",
            "        0.020994091406464577,\n",
            "        -0.03891703858971596,\n",
            "        0.016084099188447,\n",
            "        -0.01851877197623253,\n",
            "        -0.08379614353179932,\n",
            "        0.0135817751288414,\n",
            "        -0.09367556124925613,\n",
            "        0.039768557995557785,\n",
            "        0.08352406322956085,\n",
            "        0.08418048918247223,\n",
            "        -0.00614565797150135,\n",
            "        -0.02666955441236496,\n",
            "        0.012691328302025795,\n",
            "        -0.01166781410574913,\n",
            "        0.06061779707670212,\n",
            "        0.05907287448644638,\n",
            "        0.02878725714981556,\n",
            "        -0.10789306461811066,\n",
            "        0.01213577389717102,\n",
            "        0.04683390632271767,\n",
            "        0.04123400151729584,\n",
            "        0.039346374571323395,\n",
            "        0.04129791259765625,\n",
            "        0.041813239455223083,\n",
            "        0.03260728716850281,\n",
            "        0.029555603861808777,\n",
            "        0.008074724115431309,\n",
            "        0.14135274291038513,\n",
            "        0.0623096339404583,\n",
            "        0.1001492515206337,\n",
            "        0.0070272465236485004\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "\n",
            "======================================================================\n",
            "INITIALIZING RAG SYSTEM\n",
            "======================================================================\n",
            "âœ“ RAG system initialized with groq backend\n",
            "  Model: llama-3.1-8b-instant\n",
            "\n",
            "ðŸ§ª Testing Groq API connection...\n",
            "âœ… API working! Response: Hi.\n",
            "âœ“ Complete RAG pipeline initialized\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE QUERIES\n",
            "======================================================================\n",
            "\n",
            "--- Example 1: Disease Mechanism ---\n",
            "\n",
            "ðŸ” Processing: What causes jaundice in cirrhosis?\n",
            "ðŸ“Š Searching knowledge graph for: cirrhosis\n",
            "âœ“ Retrieved context (2089 chars)\n",
            "ðŸ¤– Generating answer...\n",
            "âœ“ Answer generated\n",
            "\n",
            "ðŸ“ Question: What causes jaundice in cirrhosis?\n",
            "ðŸ¤– Model: llama-3.1-8b-instant\n",
            "ðŸ“Š Context length: 2089 chars\n",
            "ðŸ’¡ Answer:\n",
            "The provided context does not directly mention the causes of jaundice in cirrhosis. However, it does mention cirrhosis as a cause of hepatic edema (edema of the liver) and ascites (fluid accumulation in the abdomen). \n",
            "\n",
            "Jaundice is often associated with liver diseases, including cirrhosis, due to impaired liver function and bile flow. However, the specific causes of jaundice in cirrhosis are not mentioned in the provided context.\n",
            "\n",
            "--- Example 2: Drug Mechanism ---\n",
            "\n",
            "ðŸ” Processing: How does metformin work?\n",
            "ðŸ“Š Searching knowledge graph for: metformin\n",
            "âœ“ Retrieved context (1892 chars)\n",
            "ðŸ¤– Generating answer...\n",
            "âœ“ Answer generated\n",
            "\n",
            "ðŸ“ Question: How does metformin work?\n",
            "ðŸ’¡ Answer:\n",
            "Based on the provided knowledge graph context, metformin is mentioned as a medication acting on the gastrointestinal system, effective for weight control in patients with type 2 diabetes and polycystic ovary syndrome. However, the context does not explicitly explain how metformin works.\n",
            "\n",
            "Therefore, I must say that the context does not contain enough information to provide a clear explanation of how metformin works.\n",
            "\n",
            "--- Example 3: Simple Query ---\n",
            "\n",
            "ðŸ” Processing: What are common diabetes symptoms?\n",
            "ðŸ“Š Searching knowledge graph for: diabetes\n",
            "âœ“ Retrieved context (1485 chars)\n",
            "ðŸ¤– Generating answer...\n",
            "âœ“ Answer generated\n",
            "\n",
            "ðŸ“ Question: What are common diabetes symptoms?\n",
            "ðŸ’¡ Answer:\n",
            "Based on the provided knowledge graph context, diabetes is mentioned as a condition that causes weight loss due to the large amounts of glucose excreted in urine. However, the context does not provide a comprehensive list of common diabetes symptoms.\n",
            "\n",
            "From the given information, we can infer that one symptom of diabetes is weight loss.\n",
            "\n",
            "======================================================================\n",
            "INTERACTIVE MODE\n",
            "======================================================================\n",
            "\n",
            "âœ¨ Uncomment the code below to enable interactive Q&A:\n",
            "\n",
            "# Interactive loop\n",
            "while True:\n",
            "    q = input(\"\\n\\nYour question (or 'quit'): \")\n",
            "    if q.lower() in ['quit', 'exit', 'q']:\n",
            "        break\n",
            "    entity = input(\"Entity to search (or Enter to auto-detect): \").strip() or None\n",
            "    result = pipeline.ask(q, entity=entity)\n",
            "    print(f\"\\nðŸ’¡ Answer:\\n{result['answer']}\")\n",
            "    print(f\"\\nðŸ“Š Used {result['context_length']} chars of context\")\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ADVANCED: MODEL SWITCHING\n",
            "======================================================================\n",
            "\n",
            "ðŸ”§ You can switch models dynamically:\n",
            "\n",
            "# Example: Try different Groq models\n",
            "rag_fast = BiomedicalRAG(backend=\"groq\", api_key=GROQ_KEY, model=\"llama-3.1-8b-instant\")\n",
            "pipeline_fast = CompleteRAGPipeline(neo4j, rag_fast)\n",
            "\n",
            "# Example: Try Gemma\n",
            "rag_gemma = BiomedicalRAG(backend=\"groq\", api_key=GROQ_KEY, model=\"gemma2-9b-it\")\n",
            "pipeline_gemma = CompleteRAGPipeline(neo4j, rag_gemma)\n",
            "\n",
            "# Example: Use HuggingFace instead\n",
            "# HF_TOKEN = \"your_token_here\"\n",
            "# rag_hf = BiomedicalRAG(backend=\"huggingface\", api_key=HF_TOKEN)\n",
            "# pipeline_hf = CompleteRAGPipeline(neo4j, rag_hf)\n",
            "\n",
            "# Example: Use local Ollama\n",
            "# rag_local = BiomedicalRAG(backend=\"ollama\", model=\"llama3.1\")\n",
            "# pipeline_local = CompleteRAGPipeline(neo4j, rag_local)\n",
            "\n",
            "\n",
            "======================================================================\n",
            "CLEANUP\n",
            "======================================================================\n",
            "âœ… All systems operational!\n",
            "ðŸ“Œ Run: pipeline.close() when done\n",
            "\n",
            "ðŸš€ Quick commands:\n",
            "   result = pipeline.ask('Your question here', entity='entity_name')\n",
            "   result = pipeline.ask('Custom query', custom_cypher='MATCH (n) RETURN n LIMIT 5')\n",
            "\n",
            "ðŸ“š Currently using Groq models (as of Oct 2024):\n",
            "   - llama-3.1-8b-instant (fast, recommended)\n",
            "   - gemma2-9b-it (alternative)\n",
            "   - mixtral-8x7b-32768 (if available)\n",
            "\n",
            "ðŸ’¡ Note: The code includes automatic fallback if a model is decommissioned!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "=============================================================================\n",
        "BIOMEDICAL RAG SYSTEM - FIXED VERSION\n",
        "Neo4j Knowledge Graph + Multi-LLM Backend\n",
        "Fixed: Updated to currently supported Groq models (October 2024)\n",
        "=============================================================================\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 1: INSTALL DEPENDENCIES\n",
        "# =============================================================================\n",
        "\n",
        "!pip install neo4j requests -q\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 2: IMPORT LIBRARIES\n",
        "# =============================================================================\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from typing import Optional, Dict, Any, List\n",
        "from neo4j import GraphDatabase\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ“ All libraries imported successfully\")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 3: NEO4J CONNECTOR CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class Neo4jConnector:\n",
        "    \"\"\"Connect to Neo4j Aura and retrieve biomedical context.\"\"\"\n",
        "\n",
        "    def __init__(self, uri: str, username: str, password: str, database: str = \"neo4j\"):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "        self.database = database\n",
        "        print(f\"âœ“ Connected to Neo4j at {uri}\")\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "        print(\"âœ“ Neo4j connection closed\")\n",
        "\n",
        "    def query(self, cypher: str, parameters: Optional[Dict] = None) -> List[Dict]:\n",
        "        \"\"\"Execute Cypher query and return results.\"\"\"\n",
        "        with self.driver.session(database=self.database) as session:\n",
        "            result = session.run(cypher, parameters or {})\n",
        "            return [record.data() for record in result]\n",
        "\n",
        "    def get_schema(self) -> str:\n",
        "        \"\"\"Retrieve database schema.\"\"\"\n",
        "        try:\n",
        "            labels_query = \"CALL db.labels() YIELD label RETURN collect(label) as labels\"\n",
        "            rels_query = \"CALL db.relationshipTypes() YIELD relationshipType RETURN collect(relationshipType) as types\"\n",
        "\n",
        "            labels = self.query(labels_query)\n",
        "            rels = self.query(rels_query)\n",
        "\n",
        "            schema = {\n",
        "                \"node_labels\": labels[0]['labels'] if labels else [],\n",
        "                \"relationship_types\": rels[0]['types'] if rels else []\n",
        "            }\n",
        "            return json.dumps(schema, indent=2)\n",
        "        except Exception as e:\n",
        "            return f\"Schema retrieval error: {e}\"\n",
        "\n",
        "    def get_sample_data(self, limit: int = 5) -> str:\n",
        "        \"\"\"Get sample nodes to understand data structure.\"\"\"\n",
        "        query = f\"\"\"\n",
        "        MATCH (n)\n",
        "        RETURN labels(n) AS labels, properties(n) AS props\n",
        "        LIMIT {limit}\n",
        "        \"\"\"\n",
        "        results = self.query(query)\n",
        "        return json.dumps(results, indent=2)\n",
        "\n",
        "    def search_entity(self, entity_name: str, limit: int = 5) -> str:\n",
        "        \"\"\"Search for entity and its relationships - optimized for context size.\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (n)\n",
        "        WHERE (n.text IS NOT NULL AND toLower(n.text) CONTAINS toLower($entity))\n",
        "           OR (n.name IS NOT NULL AND toLower(n.name) CONTAINS toLower($entity))\n",
        "           OR (n.canonical_name IS NOT NULL AND toLower(n.canonical_name) CONTAINS toLower($entity))\n",
        "        OPTIONAL MATCH (n)-[r]->(m)\n",
        "        RETURN n, labels(n) AS node_labels, r, type(r) AS rel_type, m, labels(m) AS target_labels\n",
        "        LIMIT $limit\n",
        "        \"\"\"\n",
        "\n",
        "        results = self.query(query, {\"entity\": entity_name, \"limit\": limit})\n",
        "\n",
        "        if not results:\n",
        "            return f\"No results found for '{entity_name}'.\"\n",
        "\n",
        "        # Build concise, clean context\n",
        "        context_parts = []\n",
        "\n",
        "        for idx, record in enumerate(results, 1):\n",
        "            node = record.get('n', {})\n",
        "            node_labels = record.get('node_labels', [])\n",
        "            rel_type = record.get('rel_type')\n",
        "            target = record.get('m')\n",
        "            target_labels = record.get('target_labels', [])\n",
        "\n",
        "            # Get node info (exclude embeddings)\n",
        "            node_props = {k: v for k, v in dict(node).items()\n",
        "                         if k != 'embedding' and isinstance(v, (str, int, float, bool))}\n",
        "\n",
        "            # Build node description\n",
        "            label = node_labels[0] if node_labels else \"Node\"\n",
        "\n",
        "            # Get most relevant property\n",
        "            text_prop = node_props.get('text') or node_props.get('name') or node_props.get('canonical_name') or ''\n",
        "            if text_prop and len(text_prop) > 200:\n",
        "                text_prop = text_prop[:200] + \"...\"\n",
        "\n",
        "            if text_prop:\n",
        "                context_parts.append(f\"{idx}. {label}: {text_prop}\")\n",
        "\n",
        "            # Add relationship if exists\n",
        "            if rel_type and target:\n",
        "                target_props = {k: v for k, v in dict(target).items()\n",
        "                               if k != 'embedding' and isinstance(v, (str, int, float, bool))}\n",
        "                target_text = target_props.get('text') or target_props.get('name') or target_props.get('canonical_name') or ''\n",
        "                if target_text and len(target_text) > 150:\n",
        "                    target_text = target_text[:150] + \"...\"\n",
        "\n",
        "                if target_text:\n",
        "                    target_label = target_labels[0] if target_labels else \"Node\"\n",
        "                    context_parts.append(f\"   â†’ {rel_type}: {target_label} - {target_text}\")\n",
        "\n",
        "        return \"\\n\".join(context_parts)\n",
        "\n",
        "    def custom_query_to_context(self, cypher: str, parameters: Optional[Dict] = None) -> str:\n",
        "        \"\"\"Execute custom Cypher and format as context.\"\"\"\n",
        "        results = self.query(cypher, parameters)\n",
        "\n",
        "        if not results:\n",
        "            return \"No results returned from query.\"\n",
        "\n",
        "        # Simplified formatting\n",
        "        context_parts = []\n",
        "        for i, record in enumerate(results[:10], 1):  # Limit to 10 results\n",
        "            context_parts.append(f\"{i}. {json.dumps(record)}\")\n",
        "\n",
        "        return \"\\n\".join(context_parts)\n",
        "\n",
        "print(\"âœ“ Neo4jConnector class defined\")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 4: RAG LLM BACKEND CLASS - FIXED WITH CURRENT MODELS\n",
        "# =============================================================================\n",
        "\n",
        "class BiomedicalRAG:\n",
        "    \"\"\"RAG system with CURRENT Groq models and multiple backend support.\"\"\"\n",
        "\n",
        "    def __init__(self, backend: str = \"groq\", api_key: Optional[str] = None, model: Optional[str] = None):\n",
        "        self.backend = backend\n",
        "        self.api_key = api_key\n",
        "\n",
        "        # Updated model configurations with CURRENTLY SUPPORTED models\n",
        "        self.configs = {\n",
        "            \"groq\": {\n",
        "                \"url\": \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "                \"headers\": {\n",
        "                    \"Authorization\": f\"Bearer {api_key}\",\n",
        "                    \"Content-Type\": \"application/json\"\n",
        "                } if api_key else {},\n",
        "                # FIXED: Updated to currently available models (Oct 2024)\n",
        "                \"model\": model or \"llama-3.1-70b-versatile\",  # This should still work\n",
        "                \"available_models\": [\n",
        "                    \"llama-3.1-70b-versatile\",\n",
        "                    \"llama-3.1-8b-instant\",\n",
        "                    \"llama-3.2-1b-preview\",\n",
        "                    \"llama-3.2-3b-preview\",\n",
        "                    \"llama-3.2-11b-vision-preview\",\n",
        "                    \"llama-3.2-90b-vision-preview\",\n",
        "                    \"gemma2-9b-it\",\n",
        "                    \"mixtral-8x7b-32768\"\n",
        "                ]\n",
        "            },\n",
        "            \"huggingface\": {\n",
        "                \"url\": \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "                \"headers\": {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "            },\n",
        "            \"ollama\": {\n",
        "                \"url\": \"http://localhost:11434/api/generate\",\n",
        "                \"model\": model or \"llama3.1\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        current_model = self.configs[backend].get(\"model\", \"default\")\n",
        "        print(f\"âœ“ RAG system initialized with {backend} backend\")\n",
        "        print(f\"  Model: {current_model}\")\n",
        "\n",
        "    def _build_prompt(self, question: str, context: str, max_context_length: int = 3000) -> str:\n",
        "        \"\"\"Build prompt with context length limiting.\"\"\"\n",
        "        # Truncate context if too long\n",
        "        if len(context) > max_context_length:\n",
        "            context = context[:max_context_length] + \"\\n... (truncated for length)\"\n",
        "\n",
        "        prompt = f\"\"\"You are a biomedical AI assistant. Use the provided knowledge graph context to answer the question.\n",
        "\n",
        "Context from Knowledge Graph:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Provide a clear, concise answer based ONLY on the context above. If the context doesn't contain enough information, say so.\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def _query_groq(self, prompt: str) -> str:\n",
        "        \"\"\"Query Groq API with error handling and fallback.\"\"\"\n",
        "        config = self.configs[\"groq\"]\n",
        "\n",
        "        payload = {\n",
        "            \"model\": config[\"model\"],\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"temperature\": 0.1,\n",
        "            \"max_tokens\": 500,\n",
        "            \"top_p\": 1,\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                config[\"url\"],\n",
        "                headers=config[\"headers\"],\n",
        "                json=payload,\n",
        "                timeout=30\n",
        "            )\n",
        "\n",
        "            # Enhanced error handling\n",
        "            if response.status_code != 200:\n",
        "                print(f\"âš ï¸ Error Status: {response.status_code}\")\n",
        "                try:\n",
        "                    error_json = response.json()\n",
        "                    error_msg = error_json.get('error', {}).get('message', '')\n",
        "                    print(f\"âš ï¸ Error Details: {error_msg}\")\n",
        "\n",
        "                    # Check if model is decommissioned and try fallback\n",
        "                    if 'decommissioned' in error_msg.lower():\n",
        "                        print(f\"ðŸ”„ Model '{config['model']}' is decommissioned. Trying fallback model...\")\n",
        "                        # Try llama-3.1-8b-instant as fallback\n",
        "                        config[\"model\"] = \"llama-3.1-8b-instant\"\n",
        "                        payload[\"model\"] = \"llama-3.1-8b-instant\"\n",
        "\n",
        "                        response = requests.post(\n",
        "                            config[\"url\"],\n",
        "                            headers=config[\"headers\"],\n",
        "                            json=payload,\n",
        "                            timeout=30\n",
        "                        )\n",
        "\n",
        "                        if response.status_code == 200:\n",
        "                            result = response.json()\n",
        "                            print(f\"âœ… Fallback successful! Using: {config['model']}\")\n",
        "                            return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "                        else:\n",
        "                            return f\"Groq API Error: Both primary and fallback models failed. Please check https://console.groq.com/docs/models for current models.\"\n",
        "\n",
        "                    return f\"Groq API Error: {error_msg}\"\n",
        "                except:\n",
        "                    print(f\"âš ï¸ Raw Response: {response.text[:500]}\")\n",
        "                    return f\"Groq API Error: Status {response.status_code}\"\n",
        "\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "            return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            error_detail = \"\"\n",
        "            try:\n",
        "                error_detail = response.json()\n",
        "                if 'error' in error_detail:\n",
        "                    error_msg = error_detail['error'].get('message', str(e))\n",
        "                    return f\"Groq API Error: {error_msg}\\n\\nðŸ’¡ Please visit https://console.groq.com/docs/models to check available models.\"\n",
        "            except:\n",
        "                pass\n",
        "            return f\"HTTP Error {response.status_code}: {str(e)}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error querying Groq: {str(e)}\"\n",
        "\n",
        "    def _query_huggingface(self, prompt: str) -> str:\n",
        "        \"\"\"Query HuggingFace API.\"\"\"\n",
        "        config = self.configs[\"huggingface\"]\n",
        "\n",
        "        payload = {\n",
        "            \"inputs\": prompt,\n",
        "            \"parameters\": {\n",
        "                \"max_new_tokens\": 400,\n",
        "                \"temperature\": 0.1,\n",
        "                \"top_p\": 0.9,\n",
        "                \"return_full_text\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                config[\"url\"],\n",
        "                headers=config[\"headers\"],\n",
        "                json=payload,\n",
        "                timeout=30\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "\n",
        "            if isinstance(result, list) and len(result) > 0:\n",
        "                return result[0].get(\"generated_text\", \"\").strip()\n",
        "            return result.get(\"generated_text\", \"\").strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error querying HuggingFace: {str(e)}\"\n",
        "\n",
        "    def _query_ollama(self, prompt: str) -> str:\n",
        "        \"\"\"Query local Ollama instance.\"\"\"\n",
        "        config = self.configs[\"ollama\"]\n",
        "\n",
        "        payload = {\n",
        "            \"model\": config[\"model\"],\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\"temperature\": 0.1, \"num_predict\": 512}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(config[\"url\"], json=payload, timeout=60)\n",
        "            response.raise_for_status()\n",
        "            return response.json().get(\"response\", \"\").strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error querying Ollama: {str(e)}\\nMake sure Ollama is running: ollama serve\"\n",
        "\n",
        "    def answer(self, question: str, neo4j_context: str) -> Dict[str, Any]:\n",
        "        \"\"\"Generate answer using RAG pipeline.\"\"\"\n",
        "        prompt = self._build_prompt(question, neo4j_context)\n",
        "\n",
        "        if self.backend == \"groq\":\n",
        "            answer = self._query_groq(prompt)\n",
        "        elif self.backend == \"huggingface\":\n",
        "            answer = self._query_huggingface(prompt)\n",
        "        elif self.backend == \"ollama\":\n",
        "            answer = self._query_ollama(prompt)\n",
        "        else:\n",
        "            answer = f\"Unknown backend: {self.backend}\"\n",
        "\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer\": answer,\n",
        "            \"context\": neo4j_context,\n",
        "            \"backend\": self.backend,\n",
        "            \"model\": self.configs[self.backend].get(\"model\", \"N/A\"),\n",
        "            \"prompt_length\": len(prompt),\n",
        "            \"context_length\": len(neo4j_context)\n",
        "        }\n",
        "\n",
        "print(\"âœ“ BiomedicalRAG class defined with fallback support\")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 5: COMPLETE RAG PIPELINE CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class CompleteRAGPipeline:\n",
        "    \"\"\"End-to-end RAG: Neo4j â†’ Context â†’ LLM â†’ Answer\"\"\"\n",
        "\n",
        "    def __init__(self, neo4j_connector: Neo4jConnector, rag_system: BiomedicalRAG):\n",
        "        self.neo4j = neo4j_connector\n",
        "        self.rag = rag_system\n",
        "        print(\"âœ“ Complete RAG pipeline initialized\")\n",
        "\n",
        "    def ask(self, question: str, entity: Optional[str] = None,\n",
        "            custom_cypher: Optional[str] = None, cypher_params: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Answer question using full RAG pipeline.\"\"\"\n",
        "        print(f\"\\nðŸ” Processing: {question}\")\n",
        "\n",
        "        # Retrieve context from Neo4j\n",
        "        if custom_cypher:\n",
        "            print(\"ðŸ“Š Executing custom Cypher query...\")\n",
        "            context = self.neo4j.custom_query_to_context(custom_cypher, cypher_params)\n",
        "        elif entity:\n",
        "            print(f\"ðŸ“Š Searching knowledge graph for: {entity}\")\n",
        "            context = self.neo4j.search_entity(entity, limit=5)\n",
        "        else:\n",
        "            # Auto-extract entity from question\n",
        "            words = question.split()\n",
        "            potential_entities = [w.strip('?,.:;') for w in words if len(w) > 4]\n",
        "            if potential_entities:\n",
        "                entity = potential_entities[0]\n",
        "                print(f\"ðŸ“Š Auto-extracted entity: {entity}\")\n",
        "                context = self.neo4j.search_entity(entity, limit=5)\n",
        "            else:\n",
        "                context = \"No specific entity found. Please provide more context.\"\n",
        "\n",
        "        print(f\"âœ“ Retrieved context ({len(context)} chars)\")\n",
        "\n",
        "        # Generate answer with LLM\n",
        "        print(\"ðŸ¤– Generating answer...\")\n",
        "        result = self.rag.answer(question, context)\n",
        "        print(\"âœ“ Answer generated\\n\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def close(self):\n",
        "        self.neo4j.close()\n",
        "\n",
        "print(\"âœ“ CompleteRAGPipeline class defined\")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 6: CONNECT TO NEO4J\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONNECTING TO NEO4J AURA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "NEO4J_URI = \"HIDDEN\"\n",
        "NEO4J_USERNAME = \"HIDDEN\"\n",
        "NEO4J_PASSWORD = \"HIDDEN\"\n",
        "NEO4J_DATABASE = \"HIDDEN\"\n",
        "\n",
        "neo4j = Neo4jConnector(\n",
        "    uri=NEO4J_URI,\n",
        "    username=NEO4J_USERNAME,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    database=NEO4J_DATABASE\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 7: EXPLORE DATABASE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATABASE EXPLORATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nðŸ“‹ Database Schema:\")\n",
        "schema = neo4j.get_schema()\n",
        "print(schema)\n",
        "\n",
        "print(\"\\nðŸ“Š Sample Data:\")\n",
        "sample = neo4j.get_sample_data(limit=2)\n",
        "print(sample)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 8: INITIALIZE RAG SYSTEM WITH WORKING MODELS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INITIALIZING RAG SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ðŸ”´ REPLACE WITH YOUR API KEY\n",
        "GROQ_KEY = \"HIDDEN\"\n",
        "\n",
        "# FIXED: Using models that should work as of October 2024\n",
        "# Try these in order of preference:\n",
        "# 1. \"llama-3.1-8b-instant\" (Fast, reliable)\n",
        "# 2. \"gemma2-9b-it\" (Alternative)\n",
        "# 3. \"mixtral-8x7b-32768\" (If available)\n",
        "\n",
        "rag = BiomedicalRAG(\n",
        "    backend=\"groq\",\n",
        "    api_key=GROQ_KEY,\n",
        "    model=\"llama-3.1-8b-instant\"  # CHANGED: Using a model that should work\n",
        ")\n",
        "\n",
        "# Test API connection\n",
        "print(\"\\nðŸ§ª Testing Groq API connection...\")\n",
        "test_result = rag._query_groq(\"Say 'Hello' in one word.\")\n",
        "if \"Error\" not in test_result and \"API\" not in test_result:\n",
        "    print(f\"âœ… API working! Response: {test_result}\")\n",
        "else:\n",
        "    print(f\"âŒ API test failed: {test_result}\")\n",
        "    print(\"\\nðŸ’¡ Troubleshooting:\")\n",
        "    print(\"   1. Verify your API key at https://console.groq.com/keys\")\n",
        "    print(\"   2. Check current available models at https://console.groq.com/docs/models\")\n",
        "    print(\"   3. The code will automatically try fallback models\")\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = CompleteRAGPipeline(neo4j, rag)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 9: RUN EXAMPLE QUERIES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXAMPLE QUERIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Example 1\n",
        "print(\"\\n--- Example 1: Disease Mechanism ---\")\n",
        "result1 = pipeline.ask(\n",
        "    question=\"What causes jaundice in cirrhosis?\",\n",
        "    entity=\"cirrhosis\"\n",
        ")\n",
        "print(f\"ðŸ“ Question: {result1['question']}\")\n",
        "print(f\"ðŸ¤– Model: {result1['model']}\")\n",
        "print(f\"ðŸ“Š Context length: {result1['context_length']} chars\")\n",
        "print(f\"ðŸ’¡ Answer:\\n{result1['answer']}\")\n",
        "\n",
        "# Example 2\n",
        "print(\"\\n--- Example 2: Drug Mechanism ---\")\n",
        "result2 = pipeline.ask(\n",
        "    question=\"How does metformin work?\",\n",
        "    entity=\"metformin\"\n",
        ")\n",
        "print(f\"ðŸ“ Question: {result2['question']}\")\n",
        "print(f\"ðŸ’¡ Answer:\\n{result2['answer']}\")\n",
        "\n",
        "# Example 3\n",
        "print(\"\\n--- Example 3: Simple Query ---\")\n",
        "result3 = pipeline.ask(\n",
        "    question=\"What are common diabetes symptoms?\",\n",
        "    entity=\"diabetes\"\n",
        ")\n",
        "print(f\"ðŸ“ Question: {result3['question']}\")\n",
        "print(f\"ðŸ’¡ Answer:\\n{result3['answer']}\")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 10: INTERACTIVE MODE (OPTIONAL)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERACTIVE MODE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nâœ¨ Uncomment the code below to enable interactive Q&A:\")\n",
        "print(\"\"\"\n",
        "# Interactive loop\n",
        "while True:\n",
        "    q = input(\"\\\\n\\\\nYour question (or 'quit'): \")\n",
        "    if q.lower() in ['quit', 'exit', 'q']:\n",
        "        break\n",
        "    entity = input(\"Entity to search (or Enter to auto-detect): \").strip() or None\n",
        "    result = pipeline.ask(q, entity=entity)\n",
        "    print(f\"\\\\nðŸ’¡ Answer:\\\\n{result['answer']}\")\n",
        "    print(f\"\\\\nðŸ“Š Used {result['context_length']} chars of context\")\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 11: ADVANCED: SWITCH MODELS ON THE FLY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ADVANCED: MODEL SWITCHING\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nðŸ”§ You can switch models dynamically:\")\n",
        "print(\"\"\"\n",
        "# Example: Try different Groq models\n",
        "rag_fast = BiomedicalRAG(backend=\"groq\", api_key=GROQ_KEY, model=\"llama-3.1-8b-instant\")\n",
        "pipeline_fast = CompleteRAGPipeline(neo4j, rag_fast)\n",
        "\n",
        "# Example: Try Gemma\n",
        "rag_gemma = BiomedicalRAG(backend=\"groq\", api_key=GROQ_KEY, model=\"gemma2-9b-it\")\n",
        "pipeline_gemma = CompleteRAGPipeline(neo4j, rag_gemma)\n",
        "\n",
        "# Example: Use HuggingFace instead\n",
        "# HF_TOKEN = \"your_token_here\"\n",
        "# rag_hf = BiomedicalRAG(backend=\"huggingface\", api_key=HF_TOKEN)\n",
        "# pipeline_hf = CompleteRAGPipeline(neo4j, rag_hf)\n",
        "\n",
        "# Example: Use local Ollama\n",
        "# rag_local = BiomedicalRAG(backend=\"ollama\", model=\"llama3.1\")\n",
        "# pipeline_local = CompleteRAGPipeline(neo4j, rag_local)\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 12: CLEANUP\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLEANUP\")\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… All systems operational!\")\n",
        "print(\"ðŸ“Œ Run: pipeline.close() when done\")\n",
        "print(\"\\nðŸš€ Quick commands:\")\n",
        "print(\"   result = pipeline.ask('Your question here', entity='entity_name')\")\n",
        "print(\"   result = pipeline.ask('Custom query', custom_cypher='MATCH (n) RETURN n LIMIT 5')\")\n",
        "print(\"\\nðŸ“š Currently using Groq models (as of Oct 2024):\")\n",
        "print(\"   - llama-3.1-8b-instant (fast, recommended)\")\n",
        "print(\"   - gemma2-9b-it (alternative)\")\n",
        "print(\"   - mixtral-8x7b-32768 (if available)\")\n",
        "print(\"\\nðŸ’¡ Note: The code includes automatic fallback if a model is decommissioned!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
